{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marit\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "import sklearn.feature_extraction.text as sklearnText\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import re\n",
    "import string\n",
    "import difflib\n",
    "\n",
    "import pandas as pd\n",
    "def multiplier(x):\n",
    "    return x * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>merged</th>\n",
       "      <th>fuzzRatio</th>\n",
       "      <th>fuzzPartial</th>\n",
       "      <th>fuzzTokenSort</th>\n",
       "      <th>fuzzTokenSet</th>\n",
       "      <th>SMratio</th>\n",
       "      <th>clean1</th>\n",
       "      <th>clean2</th>\n",
       "      <th>SMratioClean</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>cleanMerged</th>\n",
       "      <th>cosine</th>\n",
       "      <th>cosineClean</th>\n",
       "      <th>mean Q1</th>\n",
       "      <th>mean Q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>What would a Trump presidency mean for current...</td>\n",
       "      <td>How will a Trump presidency affect the student...</td>\n",
       "      <td>What would a Trump presidency mean for current...</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>56</td>\n",
       "      <td>61</td>\n",
       "      <td>48.175182</td>\n",
       "      <td>would trump presidency mean current internatio...</td>\n",
       "      <td>trump presidency affect students presently us ...</td>\n",
       "      <td>48.175182</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>would trump presidency mean current internatio...</td>\n",
       "      <td>0.099746</td>\n",
       "      <td>0.168657</td>\n",
       "      <td>0.148489</td>\n",
       "      <td>0.140677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>Why do rockets look white?</td>\n",
       "      <td>Why are rockets and boosters painted white?</td>\n",
       "      <td>Why do rockets look white?!SPLIT!Why are rocke...</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>81</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>rockets look white</td>\n",
       "      <td>rockets boosters painted white</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>rockets look white!SPLIT!rockets boosters pain...</td>\n",
       "      <td>0.344642</td>\n",
       "      <td>0.411207</td>\n",
       "      <td>0.244901</td>\n",
       "      <td>0.290147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>What's causing someone to be jealous?</td>\n",
       "      <td>What can I do to avoid being jealous of someone?</td>\n",
       "      <td>What's causing someone to be jealous?!SPLIT!Wh...</td>\n",
       "      <td>59</td>\n",
       "      <td>65</td>\n",
       "      <td>75</td>\n",
       "      <td>78</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>whats causing someone jealous</td>\n",
       "      <td>avoid jealous someone</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>whats causing someone jealous!SPLIT!avoid jeal...</td>\n",
       "      <td>0.380817</td>\n",
       "      <td>0.411207</td>\n",
       "      <td>0.219590</td>\n",
       "      <td>0.269113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>How much is 30 kV in HP?</td>\n",
       "      <td>Where can I find a conversion chart for CC to ...</td>\n",
       "      <td>How much is 30 kV in HP?!SPLIT!Where can I fin...</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>much 30 kv hp</td>\n",
       "      <td>find conversion chart cc horsepower</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>much 30 kv hp!SPLIT!find conversion chart cc h...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165359</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>What is the best travel website in spain?</td>\n",
       "      <td>What is the best travel website?</td>\n",
       "      <td>What is the best travel website in spain?!SPLI...</td>\n",
       "      <td>88</td>\n",
       "      <td>97</td>\n",
       "      <td>87</td>\n",
       "      <td>100</td>\n",
       "      <td>86.363636</td>\n",
       "      <td>best travel website spain</td>\n",
       "      <td>best travel website</td>\n",
       "      <td>86.363636</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>best travel website spain!SPLIT!best travel we...</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.349145</td>\n",
       "      <td>0.306186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  test_id  \\\n",
       "0           0             0       15   \n",
       "1           1             1       20   \n",
       "2           2             2       21   \n",
       "3           3             3       23   \n",
       "4           4             4       34   \n",
       "\n",
       "                                           question1  \\\n",
       "0  What would a Trump presidency mean for current...   \n",
       "1                         Why do rockets look white?   \n",
       "2              What's causing someone to be jealous?   \n",
       "3                           How much is 30 kV in HP?   \n",
       "4          What is the best travel website in spain?   \n",
       "\n",
       "                                           question2  \\\n",
       "0  How will a Trump presidency affect the student...   \n",
       "1        Why are rockets and boosters painted white?   \n",
       "2   What can I do to avoid being jealous of someone?   \n",
       "3  Where can I find a conversion chart for CC to ...   \n",
       "4                   What is the best travel website?   \n",
       "\n",
       "                                              merged  fuzzRatio  fuzzPartial  \\\n",
       "0  What would a Trump presidency mean for current...         53           54   \n",
       "1  Why do rockets look white?!SPLIT!Why are rocke...         64           65   \n",
       "2  What's causing someone to be jealous?!SPLIT!Wh...         59           65   \n",
       "3  How much is 30 kV in HP?!SPLIT!Where can I fin...         25           33   \n",
       "4  What is the best travel website in spain?!SPLI...         88           97   \n",
       "\n",
       "   fuzzTokenSort  fuzzTokenSet    SMratio  \\\n",
       "0             56            61  48.175182   \n",
       "1             66            81  66.666667   \n",
       "2             75            78  52.000000   \n",
       "3             30            30  25.000000   \n",
       "4             87           100  86.363636   \n",
       "\n",
       "                                              clean1  \\\n",
       "0  would trump presidency mean current internatio...   \n",
       "1                                 rockets look white   \n",
       "2                      whats causing someone jealous   \n",
       "3                                      much 30 kv hp   \n",
       "4                          best travel website spain   \n",
       "\n",
       "                                              clean2  SMratioClean   jaccard  \\\n",
       "0  trump presidency affect students presently us ...     48.175182  0.161290   \n",
       "1                     rockets boosters painted white     66.666667  0.400000   \n",
       "2                              avoid jealous someone     52.000000  0.357143   \n",
       "3                find conversion chart cc horsepower     25.000000  0.052632   \n",
       "4                                best travel website     86.363636  0.777778   \n",
       "\n",
       "                                         cleanMerged    cosine  cosineClean  \\\n",
       "0  would trump presidency mean current internatio...  0.099746     0.168657   \n",
       "1  rockets look white!SPLIT!rockets boosters pain...  0.344642     0.411207   \n",
       "2  whats causing someone jealous!SPLIT!avoid jeal...  0.380817     0.411207   \n",
       "3  much 30 kv hp!SPLIT!find conversion chart cc h...  0.000000     0.000000   \n",
       "4  best travel website spain!SPLIT!best travel we...  0.776515     0.776515   \n",
       "\n",
       "    mean Q1   mean Q2  \n",
       "0  0.148489  0.140677  \n",
       "1  0.244901  0.290147  \n",
       "2  0.219590  0.269113  \n",
       "3  0.165359  0.187500  \n",
       "4  0.349145  0.306186  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIER EVEN JE CSV DIE JE GISTER MAAKTE EN OP DRIVE ZETTEN GOOIEN\n",
    "test_data = pd.read_csv(\"Data/testsetlol.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate_x</th>\n",
       "      <th>is_duplicate_y</th>\n",
       "      <th>merged</th>\n",
       "      <th>...</th>\n",
       "      <th>SMratio</th>\n",
       "      <th>clean1</th>\n",
       "      <th>clean2</th>\n",
       "      <th>SMratioClean</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>cleanMerged</th>\n",
       "      <th>cosine</th>\n",
       "      <th>cosineClean</th>\n",
       "      <th>mean Q1</th>\n",
       "      <th>mean Q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>...</td>\n",
       "      <td>92.105263</td>\n",
       "      <td>step step guide invest share market india</td>\n",
       "      <td>step step guide invest share market</td>\n",
       "      <td>92.105263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>step step guide invest share market india!SPLI...</td>\n",
       "      <td>0.920307</td>\n",
       "      <td>0.895532</td>\n",
       "      <td>0.275582</td>\n",
       "      <td>0.267261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>...</td>\n",
       "      <td>59.183673</td>\n",
       "      <td>story kohinoor kohinoor diamond</td>\n",
       "      <td>would happen indian government stole kohinoor ...</td>\n",
       "      <td>59.183673</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>story kohinoor kohinoor diamond!SPLIT!would ha...</td>\n",
       "      <td>0.424251</td>\n",
       "      <td>0.461171</td>\n",
       "      <td>0.184897</td>\n",
       "      <td>0.220267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>...</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>increase speed internet connection using vpn</td>\n",
       "      <td>internet speed increased hacking dns</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>increase speed internet connection using vpn!S...</td>\n",
       "      <td>0.225765</td>\n",
       "      <td>0.225765</td>\n",
       "      <td>0.190308</td>\n",
       "      <td>0.173482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>...</td>\n",
       "      <td>22.950820</td>\n",
       "      <td>mentally lonely solve</td>\n",
       "      <td>find remainder math2324math divided 2423</td>\n",
       "      <td>22.950820</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>mentally lonely solve!SPLIT!find remainder mat...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.156969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>...</td>\n",
       "      <td>24.719101</td>\n",
       "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
       "      <td>fish would survive salt water</td>\n",
       "      <td>24.719101</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
       "      <td>0.272060</td>\n",
       "      <td>0.168368</td>\n",
       "      <td>0.222979</td>\n",
       "      <td>0.162995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  id  \\\n",
       "0           0             0               0                 0   0   \n",
       "1           1             1               1                 1   1   \n",
       "2           2             2               2                 2   2   \n",
       "3           3             3               3                 3   3   \n",
       "4           4             4               4                 4   4   \n",
       "\n",
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate_x  \\\n",
       "0  What is the step by step guide to invest in sh...             NaN   \n",
       "1  What would happen if the Indian government sto...             NaN   \n",
       "2  How can Internet speed be increased by hacking...             NaN   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             NaN   \n",
       "4            Which fish would survive in salt water?             NaN   \n",
       "\n",
       "   is_duplicate_y                                             merged  \\\n",
       "0               0  What is the step by step guide to invest in sh...   \n",
       "1               0  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2               0  How can I increase the speed of my internet co...   \n",
       "3               0  Why am I mentally very lonely? How can I solve...   \n",
       "4               0  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "     ...       SMratio                                             clean1  \\\n",
       "0    ...     92.105263          step step guide invest share market india   \n",
       "1    ...     59.183673                    story kohinoor kohinoor diamond   \n",
       "2    ...     55.000000       increase speed internet connection using vpn   \n",
       "3    ...     22.950820                              mentally lonely solve   \n",
       "4    ...     24.719101  one dissolve water quikly sugar salt methane c...   \n",
       "\n",
       "                                              clean2  SMratioClean   jaccard  \\\n",
       "0                step step guide invest share market     92.105263  1.000000   \n",
       "1  would happen indian government stole kohinoor ...     59.183673  0.421053   \n",
       "2               internet speed increased hacking dns     55.000000  0.300000   \n",
       "3           find remainder math2324math divided 2423     22.950820  0.066667   \n",
       "4                      fish would survive salt water     24.719101  0.263158   \n",
       "\n",
       "                                         cleanMerged    cosine  cosineClean  \\\n",
       "0  step step guide invest share market india!SPLI...  0.920307     0.895532   \n",
       "1  story kohinoor kohinoor diamond!SPLIT!would ha...  0.424251     0.461171   \n",
       "2  increase speed internet connection using vpn!S...  0.225765     0.225765   \n",
       "3  mentally lonely solve!SPLIT!find remainder mat...  0.000000     0.000000   \n",
       "4  one dissolve water quikly sugar salt methane c...  0.272060     0.168368   \n",
       "\n",
       "    mean Q1   mean Q2  \n",
       "0  0.275582  0.267261  \n",
       "1  0.184897  0.220267  \n",
       "2  0.190308  0.173482  \n",
       "3  0.157895  0.156969  \n",
       "4  0.222979  0.162995  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIER EVEN JE CSV DIE JE GISTER MAAKTE EN OP DRIVE ZETTEN GOOIEN\n",
    "data_set = pd.read_csv(\"Data/datasettrainlol.csv\")\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalen\n",
    "data_set['jaccard'] = data_set['jaccard'].apply(multiplier)\n",
    "data_set['cosine'] = data_set['cosine'].apply(multiplier)\n",
    "data_set['cosineClean'] = data_set['cosineClean'].apply(multiplier)\n",
    "test_data['jaccard'] = test_data['jaccard'].apply(multiplier)\n",
    "test_data['cosine'] = test_data['cosine'].apply(multiplier)\n",
    "test_data['cosineClean'] = test_data['cosineClean'].apply(multiplier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SITUATIES:\n",
    "| **RF**|**Features Countvec**| **AC bekend**|\n",
    "|--------|------|-----|\n",
    "|50|100|0.78|\n",
    "|100|100|0.79|\n",
    "|50|500|0.80|\n",
    "|75|250||\n",
    "|75|400||\n",
    "|75|500||\n",
    "|75|650||\n",
    "|75|800||\n",
    "|75|1000||\n",
    "|75|1250||\n",
    "|75|1500||\n",
    "|75|2000||\n",
    "|75|5000||\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leukefunctienaam(COUNT, ESTIMATORS, FILENAME):\n",
    "    # TEST\n",
    "    vectorizer = CountVectorizer(max_features=COUNT)\n",
    "    features = vectorizer.fit_transform(data_set.merged.values.astype('U'))\n",
    "    X = vectorizer.transform(data_set.merged.values.astype('U'))\n",
    "    names = vectorizer.get_feature_names()\n",
    "    dense = X.todense()\n",
    "    count_vect_df = pd.DataFrame(X.todense(), columns=names)\n",
    "\n",
    "    # X_train\n",
    "    data_set2 = data_set.drop(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1', 'id', 'question1',\n",
    "           'question2', 'is_duplicate_x', 'is_duplicate_y', 'merged','cleanMerged',\n",
    "             'clean1', 'clean2'], axis=1)\n",
    "    X_train = pd.concat([data_set2, count_vect_df], axis=1)\n",
    "\n",
    "    # X_test\n",
    "    Y = vectorizer.transform(test_data.merged.values.astype('U'))\n",
    "    count_vect_dfY = pd.DataFrame(Y.todense(), columns=names)\n",
    "    test_data2 = test_data.drop(['Unnamed: 0', 'Unnamed: 0.1', 'test_id', 'question1',\n",
    "           'question2', 'merged','cleanMerged',\n",
    "             'clean1', 'clean2'], axis=1)\n",
    "    X_test = pd.concat([test_data2, count_vect_dfY], axis=1)\n",
    "\n",
    "    # Y & fill\n",
    "    y_train = data_set[['is_duplicate_y']]\n",
    "    y_test = []\n",
    "    X_train = X_train.fillna(0)\n",
    "    X_test = X_test.fillna(0)\n",
    "\n",
    "    # RFM\n",
    "    rfm = RandomForestClassifier(n_estimators=ESTIMATORS, oob_score=True, n_jobs=-1, random_state=None, max_features=None, min_samples_leaf=10)\n",
    "    rfm.fit(X_train, y_train)\n",
    "    y_pred=rfm.predict(X_train)\n",
    "    print('accuracy train:', accuracy_score(y_pred, y_train))\n",
    "    output=rfm.predict(X_test)\n",
    "    print('output:', output)\n",
    "    print('counter:', Counter(output))\n",
    "\n",
    "    # DF\n",
    "    submission = pd.concat([test_data.iloc[:, 2], pd.DataFrame(output)], axis=1, sort=False)\n",
    "    submission.head()\n",
    "\n",
    "    # CSV\n",
    "    submission.to_csv(FILENAME, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEZE STAAT ER ALS TEST\n",
    "Als je even checkt of deze runt (zou niet lang moeten duren), weet je dat die goed gaat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Marit\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Marit\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.8798348071436453\n",
      "output: [0 0 0 ... 1 1 0]\n",
      "counter: Counter({0: 49225, 1: 31901})\n"
     ]
    }
   ],
   "source": [
    "COUNT = 10\n",
    "ESTIMATORS = 10 \n",
    "FILENAME = 'result/submission-COUNT10-EST10.csv'\n",
    "leukefunctienaam(COUNT, ESTIMATORS, FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Echte test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b8e61fff50d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mESTIMATORS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m75\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mFILENAME\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'result/submission-COUNT250-EST75.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mleukefunctienaam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCOUNT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mESTIMATORS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFILENAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-5014ece9b350>\u001b[0m in \u001b[0;36mleukefunctienaam\u001b[1;34m(COUNT, ESTIMATORS, FILENAME)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# TEST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCOUNT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerged\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'U'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerged\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'U'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m--> 869\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[1;32m--> 266\u001b[1;33m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "COUNT = 250\n",
    "ESTIMATORS = 75 \n",
    "FILENAME = 'result/submission-COUNT250-EST75.csv'\n",
    "leukefunctienaam(COUNT, ESTIMATORS, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 400\n",
    "ESTIMATORS = 75 \n",
    "FILENAME = 'result/submission-COUNT400-EST75.csv'\n",
    "leukefunctienaam(COUNT, ESTIMATORS, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 500\n",
    "ESTIMATORS = 75 \n",
    "FILENAME = 'result/submission-COUNT500-EST75.csv'\n",
    "leukefunctienaam(COUNT, ESTIMATORS, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 650\n",
    "ESTIMATORS = 75 \n",
    "FILENAME = 'result/submission-COUNT650-EST75.csv'\n",
    "leukefunctienaam(COUNT, ESTIMATORS, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 800\n",
    "ESTIMATORS = 75 \n",
    "FILENAME = 'result/submission-COUNT800-EST75.csv'\n",
    "leukefunctienaam(COUNT, ESTIMATORS, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 1000\n",
    "ESTIMATORS = 75 \n",
    "FILENAME = 'result/submission-COUNT1000-EST75.csv'\n",
    "leukefunctienaam(COUNT, ESTIMATORS, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 1250\n",
    "ESTIMATORS = 75 \n",
    "FILENAME = 'result/submission-COUNT1250-EST75.csv'\n",
    "leukefunctienaam(COUNT, ESTIMATORS, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 1500\n",
    "ESTIMATORS = 75 \n",
    "FILENAME = 'result/submission-COUNT1500-EST75.csv'\n",
    "leukefunctienaam(COUNT, ESTIMATORS, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 2000\n",
    "ESTIMATORS = 75 \n",
    "FILENAME = 'result/submission-COUNT2000-EST75.csv'\n",
    "leukefunctienaam(COUNT, ESTIMATORS, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 5000\n",
    "ESTIMATORS = 75 \n",
    "FILENAME = 'result/submission-COUNT5000-EST75.csv'\n",
    "leukefunctienaam(COUNT, ESTIMATORS, FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra tests\n",
    "Ik weet niet hoe realistisch deze hieronder zijn, je moet maar even kijken of die gerunt zijn als je thuis komt. Mochten ze het doen, upload dan niet van laag naar hoog, maar beetje random wat omhoog gaat in verband met overfitten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 5000\n",
    "ESTIMATORS = 100\n",
    "FILENAME = 'result/submission-COUNT5000-EST100.csv'\n",
    "leukefunctienaam(COUNT, ESTIMATORS, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 7500\n",
    "ESTIMATORS = 75\n",
    "FILENAME = 'result/submission-COUNT7500-EST75.csv'\n",
    "leukefunctienaam(COUNT, ESTIMATORS, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 10000\n",
    "ESTIMATORS = 75\n",
    "FILENAME = 'result/submission-COUNT10000-EST75.csv'\n",
    "leukefunctienaam(COUNT, ESTIMATORS, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 12500\n",
    "ESTIMATORS = 75\n",
    "FILENAME = 'result/submission-COUNT12500-EST75.csv'\n",
    "leukefunctienaam(COUNT, ESTIMATORS, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 15000\n",
    "ESTIMATORS = 75\n",
    "FILENAME = 'result/submission-COUNT15000-EST75.csv'\n",
    "leukefunctienaam(COUNT, ESTIMATORS, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 20000\n",
    "ESTIMATORS = 75\n",
    "FILENAME = 'result/submission-COUNT20000-EST75.csv'\n",
    "leukefunctienaam(COUNT, ESTIMATORS, FILENAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
